experiment:
  number_of_epochs: 300
data:
  data: classification.datasets.ImageNet
  sampling:
    batch_size: 4096
  transforms:
    train: !!python/tuple
    - torchvision.transforms.RandomResizedCrop:
        size: 224
        scale: !!python/tuple
        - 0.8
        - 1.0
    - torchvision.transforms.RandomHorizontalFlip
    - classification.transforms.RandAugment
    - classification.transforms.OneHotEncoding
    - classification.transforms.MixupOrCutMix:
        mixup_params:
          distribution: uniform
          probability: 0.8
    - torchvision.transforms.RandomErasing:
        p: 0.25
    val: !!python/tuple
    - torchvision.transforms.Resize:
        size: 224
    - torchvision.transforms.CenterCrop:
        size: 224
    - classification.transforms.OneHotEncoding
model:
  model.FeedForwardModel:
    layers: !!python/tuple
    - segmentation.models.UNet_encoder
    - torch.nn.AdaptiveAvgPool2d:
        output_size: 1
    - torch.nn.Flatten
    - torch.nn.Linear:
        in_features: 1024
        out_features: 1000
    weight_init:
      torch.nn.init.kaiming_normal_:
        nonlinearity: relu
        mode: fan_in
training:
  loss:
    torch.nn.CrossEntropyLoss:
      label_smoothing: 0.1
      label_type: label
  optimizer:
    torch.optim.AdamW:
      learning_rate:
        optim.scheduler.SequentialLR:
          base: 0.004
          schedulers: !!python/tuple
          - optim.scheduler.LinearLR:
              start_factor: 1.0e-06
              end_factor: 1.0
          - optim.scheduler.CosineAnnealingLR:
              eta_min: 1.0e-06
          milestones: 20
          iteration_unit: batch
          milestones_unit: epoch
      betas: !!python/tuple
      - 0.9
      - 0.999
      weight_decay: 0.05
metrics:
  metrics: !!python/tuple
  - metrics.multiclass_metrics.Accuracy
  - metrics.multiclass_metrics.Top5Accuracy
  calculation:
    include_background_in_averages: true
    apply_softmax: true
    log_confusion_matrix: false
meta:
  technical:
    experiment_name: ImageNet_test_UNet_encoder
    verbose: false
    maximum_actual_batch_size: 512
    log_to_neptune: epoch
    log_to_device: epoch
    number_of_cpu_threads: 8
    model_log_checkpoints: !!python/tuple
    - 1
    - 2
    - 5
    - 10
    - 20
    - 30
    - 40
    - 50
    - 75
    - 100
    - 125
    - 150
    - 175
    - 200
    - 250
    - 300
    memory_usage_limit: 120